ğŸš¨ Guardian Grid - Detector de Gestos para EmergÃªncias
<div align="center"> <img src="https://img.shields.io/badge/Python-3.10%2B-blue"> <img src="https://img.shields.io/badge/MediaPipe-0.10.11-orange"> <img src="https://img.shields.io/badge/OpenCV-4.9.0-green"> <a href="https://youtu.be/qXyvo8B5c2I"><img src="https://img.shields.io/badge/Video_Demo-YouTube-red"></a> </div>
ğŸ“ DescriÃ§Ã£o
Sistema de reconhecimento de gestos para situaÃ§Ãµes de emergÃªncia durante apagÃµes, desenvolvido com Python e MediaPipe. Detecta gestos especÃ­ficos mesmo em ambientes com baixa luminosidade e aciona alertas sonoros.

ğŸ¥ VÃ­deo Demonstrativo
https://img.youtube.com/vi/qXyvo8B5c2I/0.jpg

ğŸ‘¥ Equipe
Nome	RM
Lucas Carlos Bandeira Teixeira	98640
JÃºlio CÃ©sar Zampieri	98772
JoÃ£o Gabriel Dias Mello do Nascimento	99092
ğŸ› ï¸ Funcionalidades
âœŠ DetecÃ§Ã£o de gestos: SOS, pedido de ajuda e confirmaÃ§Ã£o

ğŸŒ‘ OperaÃ§Ã£o em baixa luminosidade

ğŸ”‰ Alerta sonoro ao reconhecer gestos

ğŸ–¥ï¸ Interface visual em tempo real

âš™ï¸ Tecnologias
Tecnologia	VersÃ£o	Uso
Python	3.10+	LÃ³gica principal
MediaPipe	0.10.11	DetecÃ§Ã£o de gestos
OpenCV	4.9.0	Processamento de vÃ­deo
Pygame	2.5.2	ReproduÃ§Ã£o de sons
ğŸ“¦ InstalaÃ§Ã£o
Clone o repositÃ³rio:

bash
git clone https://github.com/seu-usuario/guardian-grid.git
cd guardian-grid
Instale as dependÃªncias:

bash
pip install -r requirements.txt
Execute:

bash
python gesture_detection.py
ğŸ® Como Usar
Posicione sua mÃ£o frente Ã  webcam

FaÃ§a um dos gestos:

âœŠ Punho fechado: Alerta de SOS

ğŸ¤˜ Polegar + mindinho: Pedido de ajuda

ğŸ‘Œ Sinal OK: ConfirmaÃ§Ã£o

O sistema emitirÃ¡ um alerta sonoro

ğŸ“‚ Estrutura do Projeto
text
guardian-grid/
â”œâ”€â”€ gesture_detection.py  # CÃ³digo principal
â”œâ”€â”€ alert.wav             # Som de alerta
â”œâ”€â”€ requirements.txt      # DependÃªncias
â”œâ”€â”€ README.md             # Este arquivo
â””â”€â”€ assets/               # Imagens de exemplo
ğŸ“Œ AplicaÃ§Ãµes PrÃ¡ticas
ğŸ¥ AuxÃ­lio em hospitais durante apagÃµes

ğŸ  SeguranÃ§a para idosos em residÃªncias

ğŸš¨ ComunicaÃ§Ã£o em emergÃªncias

ğŸ’» CÃ³digo Fonte
python
import cv2
import numpy as np
import mediapipe as mp
import pygame
import time

# ConfiguraÃ§Ãµes iniciais
pygame.mixer.init()
alert_sound = pygame.mixer.Sound("alert.wav")

mp_hands = mp.solutions.hands
hands = mp_hands.Hands(
    max_num_hands=1,
    min_detection_confidence=0.7,
    min_tracking_confidence=0.5
)
mp_draw = mp.solutions.drawing_utils

# Definir gestos
GESTURES = {
    "SOS": [0, 1, 1, 1, 1],        # Punho fechado
    "AJUDA": [1, 1, 0, 0, 1],      # Polegar + mindinho
    "OK": [0, 1, 1, 0, 0]          # Sinal de OK
}

def detect_gesture(hand_landmarks):
    finger_tips = [4, 8, 12, 16, 20]  # Pontas dos dedos
    finger_states = []
    
    for tip_id in finger_tips:
        # Verificar se dedo estÃ¡ levantado
        if tip_id == 4:  # Polegar
            finger_states.append(1 if hand_landmarks.landmark[tip_id].x < hand_landmarks.landmark[tip_id-1].x else 0)
        else:
            finger_states.append(1 if hand_landmarks.landmark[tip_id].y < hand_landmarks.landmark[tip_id-2].y else 0)
    
    # Identificar gesto
    for gesture, pattern in GESTURES.items():
        if finger_states == pattern:
            return gesture
    return None

def main():
    cap = cv2.VideoCapture(0)
    last_alert_time = 0
    
    while cap.isOpened():
        success, frame = cap.read()
        if not success:
            continue
        
        # Simular baixa luminosidade
        low_light = cv2.convertScaleAbs(frame, alpha=0.4, beta=0)
        
        # Detectar mÃ£os
        rgb_frame = cv2.cvtColor(low_light, cv2.COLOR_BGR2RGB)
        results = hands.process(rgb_frame)
        
        gesture_detected = None
        
        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                mp_draw.draw_landmarks(
                    low_light, hand_landmarks, mp_hands.HAND_CONNECTIONS)
                
                gesture = detect_gesture(hand_landmarks)
                if gesture:
                    gesture_detected = gesture
                    cv2.putText(low_light, f"GESTO: {gesture}", (50, 50),
                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                    
                    # Acionar alerta (com debounce)
                    if time.time() - last_alert_time > 5:
                        alert_sound.play()
                        last_alert_time = time.time()
                        print(f"ALERTA ACIONADO! Gestos: {gesture}")
        
        # Mostrar frame
        cv2.imshow('Guardian Grid - Detector de Gestos', low_light)
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
ğŸ“‹ requirements.txt
text
opencv-python==4.9.0.80
mediapipe==0.10.11
numpy==1.26.4
pygame==2.5.2
<div align="center"> Desenvolvido com â¤ï¸ por Lucas (RM98640), JÃºlio (RM98772) e JoÃ£o (RM99092) </div> ```